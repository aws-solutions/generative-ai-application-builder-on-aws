{
    "UseCase": "RAGChat",
    "ModelProviderName": "Bedrock",
    "ModelName": "meta.llama3-70b-instruct-v1:0",
    "DisplayName": "Llama 3 70B Instruct",
    "Description": "Meta Llama 3 is an accessible, open large language model (LLM) designed for developers, researchers, and businesses to build, experiment, and responsibly scale their generative AI ideas. Part of a foundational system, it serves as a bedrock for innovation in the global community. Ideal for content creation, conversational AI, language understanding, R&D, and Enterprise applications.",
    "AllowsStreaming": true,
    "Prompt": "References:\n{context}\n\nCarefully read the reference passages above and try to truthfully answer the Human's question. If the answer is not explicitly contained within the references, respond with \"Sorry I don't know\". It is very important that you respond \"Sorry I don't know\" if the answer is not found within the references above. Do not make use of any information outside of the references. Try to be brief and write a response in no more than 5 complete sentences.",
    "DisambiguationPrompt": "Given the following conversation and a follow up question, rephrase the follow up question to be a standalone question, in its original language.\n\nChat History:\n{history}\nFollow Up Input: {input}\nStandalone question:",
    "MaxTemperature": "1",
    "DefaultTemperature": "0.5",
    "MinTemperature": "0",
    "DefaultStopSequences": [],
    "MemoryConfig": {
        "history": "history",
        "input": "input",
        "context": "context",
        "ai_prefix": "AI",
        "human_prefix": "Human",
        "output": "answer"
    },
    "MaxPromptSize": 15000,
    "MaxChatMessageSize": 15000
}