{
    "UseCase": "RAGChat",
    "ModelProviderName": "Bedrock",
    "ModelName": "anthropic.claude-3-haiku-20240307-v1:0",
    "DisplayName": "Claude 3 Haiku",
    "Description": "Claude 3 Haiku is Anthropic's fastest, most compact model for near-instant responsiveness. It answers simple queries and requests with speed. Customers will be able to build seamless AI experiences that mimic human interactions. Claude 3 Haiku can process images and return text outputs, and features a 200K context window.",
    "AllowsStreaming": true,
    "Prompt": "\n\nYou are a friendly AI assistant. You provide answers only based on the provided reference passages.\n\nHere are reference passages in <references></references> tags:\n<references>\n{context}\n</references>\n\nCarefully read the references above and thoughtfully answer the question below. If the answer can not be extracted from the references, then respond with \"Sorry I don't know\". It is very important that you only use information found within the references to answer. Try to be brief in your response.",
    "DisambiguationPrompt": "\n\nHuman: Given the following conversation and a follow up question, rephrase the follow up question to be a standalone question.\n\nChat history:\n{history}\n\nFollow up question: {input}\n\nAssistant: Standalone question:",
    "MaxTemperature": "1",
    "DefaultTemperature": "1",
    "MinTemperature": "0",
    "DefaultStopSequences": [],
    "MemoryConfig": {
        "history": "history",
        "input": "input",
        "context": "context",
        "ai_prefix": "A",
        "human_prefix": "H",
        "output": "answer"
    },
    "MaxPromptSize": 375000,
    "MaxChatMessageSize": 375000
}